# ğŸµ Classificador de Ãudio com Deep Learning

Este projeto implementa um sistema completo de classificaÃ§Ã£o de Ã¡udio usando mel-espectrogramas e espectrogramas lineares (STFT) com CNNs e Transfer Learning.

## ğŸ“‹ CaracterÃ­sticas

- **Processamento de Ãudio**: ConversÃ£o de arquivos de Ã¡udio em mel-espectrogramas e espectrogramas STFT
- **Transfer Learning**: Utiliza ResNet18 prÃ©-treinada para classificaÃ§Ã£o de imagens de espectrogramas
- **Ensemble Learning**: Combina prediÃ§Ãµes de ambos os modelos para melhor performance
- **Interface Web**: Interface Streamlit para classificaÃ§Ã£o em tempo real
- **MÃ©tricas Detalhadas**: AvaliaÃ§Ã£o completa com relatÃ³rios de classificaÃ§Ã£o

## ğŸš€ InstalaÃ§Ã£o

1. Clone ou baixe os arquivos do projeto
2. Instale as dependÃªncias:

```bash
pip install -r requirements.txt
```

## ğŸ“ Estrutura do Projeto

```
â”œâ”€â”€ audio_classifier.py      # Script principal de treinamento
â”œâ”€â”€ real_time_interface.py   # Interface web Streamlit
â”œâ”€â”€ requirements.txt         # DependÃªncias do projeto
â”œâ”€â”€ README.md               # DocumentaÃ§Ã£o
â””â”€â”€ data/                   # DiretÃ³rio para dados de treinamento
    â”œâ”€â”€ mel_spectrograms/   # Imagens de mel-espectrogramas
    â””â”€â”€ stft_spectrograms/  # Imagens de espectrogramas STFT
```

## ğŸ¯ Como Usar

### 1. PreparaÃ§Ã£o dos Dados

Organize seus dados de Ã¡udio da seguinte forma:

```
data/
â”œâ”€â”€ mel_spectrograms/
â”‚   â”œâ”€â”€ classe_a/
â”‚   â”‚   â”œâ”€â”€ audio1_mel.png
â”‚   â”‚   â””â”€â”€ audio2_mel.png
â”‚   â””â”€â”€ classe_b/
â”‚       â”œâ”€â”€ audio3_mel.png
â”‚       â””â”€â”€ audio4_mel.png
â””â”€â”€ stft_spectrograms/
    â”œâ”€â”€ classe_a/
    â”‚   â”œâ”€â”€ audio1_stft.png
    â”‚   â””â”€â”€ audio2_stft.png
    â””â”€â”€ classe_b/
        â”œâ”€â”€ audio3_stft.png
        â””â”€â”€ audio4_stft.png
```

### 2. Treinamento dos Modelos

Execute o script principal para treinar os modelos:

```bash
python audio_classifier.py
```

Este script irÃ¡:
- Gerar dados dummy para demonstraÃ§Ã£o (substitua pelos seus dados reais)
- Treinar modelos separados para mel-espectrogramas e STFT
- Avaliar a performance de cada modelo
- Criar e avaliar o modelo ensemble
- Salvar os modelos treinados

### 3. Interface Web

ApÃ³s o treinamento, execute a interface web:

```bash
streamlit run real_time_interface.py
```

A interface permite:
- Upload de arquivos de Ã¡udio (WAV, MP3, FLAC, M4A)
- VisualizaÃ§Ã£o dos espectrogramas gerados
- ClassificaÃ§Ã£o usando os trÃªs modelos (Mel, STFT, Ensemble)
- ComparaÃ§Ã£o de confianÃ§a entre os mÃ©todos

## ğŸ”§ Funcionalidades Principais

### Processamento de Ãudio

```python
# Gerar mel-espectrograma
mel_spec = create_mel_spectrogram(audio_path)

# Gerar espectrograma STFT
stft_spec = create_stft_spectrogram(audio_path)

# Salvar como imagem
save_spectrogram_as_image(mel_spec, 'output.png')
```

### Transfer Learning

- Utiliza ResNet18 prÃ©-treinada do PyTorch
- Substitui a camada final para o nÃºmero de classes do problema
- Treina apenas a camada de classificaÃ§Ã£o final

### Ensemble Model

```python
# Combina prediÃ§Ãµes de ambos os modelos
ensemble_model = EnsembleModel(mel_model, stft_model, num_classes)
```

## ğŸ“Š AvaliaÃ§Ã£o

O sistema fornece:
- **AcurÃ¡cia** para cada modelo individual
- **RelatÃ³rio de classificaÃ§Ã£o** detalhado
- **ComparaÃ§Ã£o de confianÃ§a** entre mÃ©todos
- **VisualizaÃ§Ã£o** dos espectrogramas

## ğŸ§ Tipos de Espectrogramas

### Mel-espectrogramas
- RepresentaÃ§Ã£o baseada na escala mel (percepÃ§Ã£o auditiva humana)
- Melhor para caracterÃ­sticas perceptuais do Ã¡udio
- Comumente usado em reconhecimento de fala

### Espectrogramas STFT
- Transformada de Fourier de Tempo Curto
- RepresentaÃ§Ã£o linear da frequÃªncia
- Preserva mais detalhes espectrais

## âš™ï¸ ConfiguraÃ§Ãµes

### ParÃ¢metros de Ãudio
- **Taxa de amostragem**: 22050 Hz
- **N_mels**: 128 (mel-espectrograma)
- **N_fft**: 2048 (STFT)
- **Hop_length**: 512

### ParÃ¢metros de Treinamento
- **Batch size**: 4
- **Learning rate**: 0.001
- **Optimizer**: Adam
- **Ã‰pocas**: 25 (configurÃ¡vel)

## ğŸ”„ Fluxo de Trabalho

1. **Carregamento**: Ãudio â†’ Librosa
2. **ConversÃ£o**: Ãudio â†’ Espectrogramas (Mel + STFT)
3. **VisualizaÃ§Ã£o**: Espectrogramas â†’ Imagens PNG
4. **Treinamento**: Imagens â†’ CNN (ResNet18)
5. **Ensemble**: CombinaÃ§Ã£o dos modelos
6. **InferÃªncia**: Novo Ã¡udio â†’ ClassificaÃ§Ã£o

## ğŸš¨ Notas Importantes

- **Dados Dummy**: O script atual gera dados fictÃ­cios para demonstraÃ§Ã£o
- **Dados Reais**: Substitua pela sua estrutura de dados real
- **Classes**: Adapte o nÃºmero de classes conforme seu problema
- **Hardware**: GPU recomendada para treinamento mais rÃ¡pido

## ğŸ”§ PersonalizaÃ§Ã£o

### Adicionar Novas Classes
1. Modifique a estrutura de diretÃ³rios
2. Ajuste `num_classes` no cÃ³digo
3. Atualize `class_names` na interface

### Modificar Arquitetura
- Substitua ResNet18 por outros modelos (ResNet50, EfficientNet, etc.)
- Ajuste a camada de ensemble para combinaÃ§Ãµes mais complexas

### Otimizar Performance
- Aumente o nÃºmero de Ã©pocas
- Ajuste learning rate
- Implemente data augmentation
- Use tÃ©cnicas de regularizaÃ§Ã£o

## ğŸ“ˆ Resultados Esperados

O sistema fornece trÃªs tipos de prediÃ§Ã£o:
- **Mel-espectrograma**: Focado em caracterÃ­sticas perceptuais
- **STFT**: Focado em caracterÃ­sticas espectrais detalhadas
- **Ensemble**: CombinaÃ§Ã£o otimizada de ambos

## ğŸ¤ ContribuiÃ§Ãµes

Para melhorar o sistema:
1. Implemente data augmentation
2. Adicione mais arquiteturas de rede
3. Otimize hiperparÃ¢metros
4. Adicione suporte a mais formatos de Ã¡udio

## ğŸ“ LicenÃ§a

Este projeto Ã© fornecido como exemplo educacional. Adapte conforme necessÃ¡rio para seus casos de uso especÃ­ficos.

